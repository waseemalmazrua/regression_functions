from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd


def run_logistic_regression(X, y):
    # 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ù…ØªØºÙŠØ±Ø§Øª Ø±Ù‚Ù…ÙŠØ©
    X_encoded = pd.get_dummies(X, drop_first=True)

    # 2. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = LogisticRegression(max_iter=1000)
    model.fit(X_encoded, y)

    # 3. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    predictions = model.predict(X_encoded)

    # 4. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print(" Logistic Regression Results")
    print("Intercept:", model.intercept_)
    print("Coefficients:", model.coef_)
    print("Accuracy:", accuracy_score(y, predictions))
    print("Confusion Matrix:\n", confusion_matrix(y, predictions))
    print("Classification Report:\n", classification_report(y, predictions))

    return model


def run_linear_regression(X, y):
    
    
    ÙŠØ¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… one-hot encoding).
    
    Parameters:
    X -- DataFrame: Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø© (Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© ÙØ¦ÙˆÙŠØ©)
    y -- Series: Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹ (Ø±Ù‚Ù…ÙŠ)

    Returns:
    model -- Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ù† Ù†ÙˆØ¹ LinearRegression
    """
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
    X_encoded = pd.get_dummies(X, drop_first=True)

    model = LinearRegression()
    model.fit(X_encoded, y)
    predictions = model.predict(X_encoded)

    print("ğŸ“ˆ Linear Regression Results")
    print("Intercept:", model.intercept_)
    print("Coefficients:")
    for feature, coef in zip(X_encoded.columns, model.coef_):
        print(f"  {feature}: {coef:.4f}")

    print("RÂ² Score:", r2_score(y, predictions))
    print("Mean Squared Error:", mean_squared_error(y, predictions))

    return model
