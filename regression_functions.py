# ğŸ“¦ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    r2_score, mean_squared_error
)
from sklearn import set_config
import pandas as pd
import numpy as np

# Ù„Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù€ Pipeline Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù…
set_config(transform_output="pandas")

# ğŸ“Œ Logistic Regression Pipeline

def run_pipeline_logistic_regression(df, target_col, test_size=0.2, random_state=42):
    """
    ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Logistic Regression Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pipeline.
    ÙŠØ´Ù…Ù„: OneHotEncoder Ù„Ù„ÙØ¦ÙˆÙŠØ©ØŒ StandardScaler Ù„Ù„Ø±Ù‚Ù…ÙŠØ©.
    ÙŠÙ‚Ø¨Ù„ Ø£ÙŠ DataFrame ÙˆÙŠØ­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.
    """
    # ÙØµÙ„ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù Ø¹Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª
    X = df.drop(columns=[target_col])
    y_raw = df[target_col]

    # ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© Ø¥Ù† ÙƒØ§Ù†Øª Ù†ØµÙŠØ©
    if y_raw.dtype == 'object':
        y = y_raw.map({val: i for i, val in enumerate(y_raw.unique())})
    else:
        y = y_raw

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ ColumnTransformer
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)
    ])

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ Pipeline
    pipeline = Pipeline([
        ('preprocessing', preprocessor),
        ('classifier', LogisticRegression(max_iter=1000))
    ])

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    pipeline.fit(X_train, y_train)

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    y_train_pred = pipeline.predict(X_train)
    y_test_pred = pipeline.predict(X_test)

    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
    print("\nğŸ“Š Logistic Regression Results")
    print("Train Accuracy:", accuracy_score(y_train, y_train_pred))
    print("Test Accuracy :", accuracy_score(y_test, y_test_pred))
    print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_test_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_test_pred))

    return pipeline







from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier

def run_pipeline_random_forest_classification(df, target_col, test_size=0.2, random_state=42):
    """
    ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Classifier Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pipeline.
    ØªØ´Ù…Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: OneHotEncoder Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©ØŒ StandardScaler Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©.
    """
    # ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù
    X = df.drop(columns=[target_col])
    y_raw = df[target_col]

    # ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù‡Ø¯Ù Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù†ØµÙŠØ© (Ù…Ø«Ù„Ø§Ù‹: Yes/No)
    y = y_raw.map({'No': 0, 'Yes': 1}) if y_raw.dtype == 'object' else y_raw

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„ÙØ¦ÙˆÙŠØ©
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©
    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ])

    # Ø¨Ø§ÙŠØ¨Ù„Ø§ÙŠÙ† Ø§Ù„ØªØµÙ†ÙŠÙ
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=random_state))
    ])

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    pipeline.fit(X_train, y_train)

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    y_pred = pipeline.predict(X_test)

    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    print("ğŸ¯ Random Forest Classification Results")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))

    return pipeline












# ğŸ“Œ Linear Regression Pipeline

def run_pipeline_linear_regression(df, target_col, test_size=0.2, random_state=42):
    """
    ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Linear Regression Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pipeline.
    ÙŠØ´Ù…Ù„: OneHotEncoder Ù„Ù„ÙØ¦ÙˆÙŠØ©ØŒ StandardScaler Ù„Ù„Ø±Ù‚Ù…ÙŠØ©.
    ÙŠÙ‚Ø¨Ù„ Ø£ÙŠ DataFrame ÙˆÙŠØ­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.
    """
    # ÙØµÙ„ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù Ø¹Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª
    X = df.drop(columns=[target_col])
    y = df[target_col]

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ ColumnTransformer
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)
    ])

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ Pipeline
    pipeline = Pipeline([
        ('preprocessing', preprocessor),
        ('regressor', LinearRegression())
    ])

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    pipeline.fit(X_train, y_train)

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    y_train_pred = pipeline.predict(X_train)
    y_test_pred = pipeline.predict(X_test)

    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
    print("\nğŸ“ˆ Linear Regression Results")
    print("Train RÂ² Score:", r2_score(y_train, y_train_pred))
    print("Test RÂ² Score :", r2_score(y_test, y_test_pred))
    print("Test Mean Squared Error:", mean_squared_error(y_test, y_test_pred))

    return pipeline






from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestRegressor

def run_pipeline_random_forest_regression(df, target_col, test_size=0.2, random_state=42):
    """
    ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Regressor Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pipeline.
    ØªØ´Ù…Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: OneHotEncoder Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©ØŒ StandardScaler Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©.
    """
    # ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù
    X = df.drop(columns=[target_col])
    y = df[target_col]

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„ÙØ¦ÙˆÙŠØ©
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø¨Ù‚
    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ])

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø§ÙŠØ¨Ù„Ø§ÙŠÙ†
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', RandomForestRegressor(n_estimators=100, random_state=random_state))
    ])

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    pipeline.fit(X_train, y_train)

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    y_pred = pipeline.predict(X_test)

    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    print("ğŸ¯ Random Forest Regression Results")
    print("RÂ² Score:", r2_score(y_test, y_pred))
    print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

    return pipeline

